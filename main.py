import yt_dlp
from pydub import AudioSegment
import subprocess
import json
import os
import re
import trafilatura
import uuid
import requests
from openai import OpenAI
from markitdown import MarkItDown
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import CommandHandler, MessageHandler, CallbackQueryHandler, filters, ApplicationBuilder
from bs4 import BeautifulSoup
from telegram.helpers import escape_markdown
from pymongo import MongoClient
from datetime import datetime
import feedparser
import markdown
import jieba
import jieba.analyse

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText

# å¾ç’°å¢ƒè®Šæ•¸ä¸­æå– SMTP è¨­å®š
smtp_server = os.environ.get("SMTP_SERVER", "smtp.gmail.com")
smtp_port = int(os.environ.get("SMTP_PORT", 465))  # é è¨­ä½¿ç”¨ SSL
smtp_user = os.environ.get("SMTP_USER", "your_email@gmail.com")
smtp_password = os.environ.get("SMTP_PASSWORD", "your_password")
smtp_cc_emails = os.environ.get("SMTP_CC_EMAILS", "").split(",")  # å¤šå€‹ CC æ”¶ä»¶äººä»¥é€—è™Ÿåˆ†éš”
enable_email = int(os.environ.get("ENABLE_EMAIL", 0))  # æ§åˆ¶æ˜¯å¦å•Ÿç”¨ç™¼é€éƒµä»¶åŠŸèƒ½ï¼Œé»˜èªç‚º 0ï¼ˆç¦ç”¨ï¼‰
# discord è¨­å®š
discord_webhook_url = os.environ.get("DISCORD_WEBHOOK_URL", "")
enable_discord_webhook = int(os.environ.get("ENABLE_DISCORD_WEBHOOK", 0)) # é»˜èªç‚º 0ï¼ˆä¸å•Ÿç”¨ï¼‰



def send_to_discord(content):
    """
    ç™¼é€è¨Šæ¯åˆ° Discord Webhook
    å¦‚æœå…§å®¹éé•·ï¼Œæœƒè‡ªå‹•ä¸Šå‚³ç‚º txt æ–‡ä»¶
    """
    if not enable_discord_webhook:
        print("Discord Webhook is disabled by configuration.")
        return  # å¦‚æœ Webhook åŠŸèƒ½è¢«ç¦ç”¨ï¼Œç›´æ¥è¿”å›
    
    if not discord_webhook_url:
        print("Discord Webhook URL is not set.")
        return
    
    try:
        # Discord è¨Šæ¯é•·åº¦é™åˆ¶ç‚º 2000 å­—ç¬¦
        max_length = 1900  # ç•™ä¸€äº›ç·©è¡ç©ºé–“
        
        if len(content) <= max_length:
            # å…§å®¹ä¸é•·ï¼Œç›´æ¥ç™¼é€æ–‡å­—è¨Šæ¯
            data = {"content": content}
            response = requests.post(discord_webhook_url, json=data)
            response.raise_for_status()
            print("Message sent to Discord successfully.")
        else:
            # å…§å®¹éé•·ï¼Œä¸Šå‚³ç‚º txt æ–‡ä»¶
            temp_file_path = f"/tmp/discord_summary_{uuid.uuid4()}.txt"
            
            # å‰µå»º txt æ–‡ä»¶
            with open(temp_file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # æº–å‚™ä¸Šå‚³æ–‡ä»¶çš„æ•¸æ“š
            with open(temp_file_path, 'rb') as f:
                files = {
                    'file': ('summary.txt', f, 'text/plain')
                }
                data = {
                    'content': 'ğŸ“„ æ‘˜è¦å…§å®¹éé•·ï¼Œå·²ä¸Šå‚³ç‚ºæ–‡ä»¶'
                }
                
                response = requests.post(discord_webhook_url, data=data, files=files)
                response.raise_for_status()
            
            # åˆªé™¤è‡¨æ™‚æ–‡ä»¶
            os.remove(temp_file_path)
            print("File sent to Discord successfully.")
            
    except requests.exceptions.RequestException as e:
        print(f"Failed to send message to Discord: {e}")
    except Exception as e:
        print(f"Error in send_to_discord: {e}")


def send_summary_via_email(summary, recipient_email, subject="æ‘˜è¦çµæœ"):
    if not enable_email:
        print("Email sending is disabled by configuration.")
        return  # å¦‚æœç¦ç”¨éƒµä»¶åŠŸèƒ½ï¼Œç›´æ¥è¿”å›
    
    try:
        # æª¢æŸ¥å¿…è¦çš„éƒµä»¶è¨­å®š
        if not smtp_server or not smtp_user or not smtp_password:
            print("éƒµä»¶è¨­å®šä¸å®Œæ•´ï¼Œç„¡æ³•ç™¼é€éƒµä»¶")
            return
            
        # è¨­å®šéƒµä»¶ä¸»é«”
        message = MIMEMultipart()
        message["From"] = smtp_user
        message["To"] = recipient_email
        
        # åªæœ‰åœ¨æœ‰æŠ„é€æ”¶ä»¶äººæ™‚æ‰æ·»åŠ  CC æ¬„ä½
        if smtp_cc_emails and any(smtp_cc_emails):
            message["CC"] = ", ".join(smtp_cc_emails)
            all_recipients = [recipient_email] + smtp_cc_emails
        else:
            all_recipients = [recipient_email]
            
        message["Subject"] = subject

        # æ·»åŠ éƒµä»¶æ­£æ–‡ (è½‰ç‚º HTML ä»¥æ”¯æ´ Markdown æ’ç‰ˆ)
        html_summary = markdown.markdown(summary, extensions=['nl2br'])
        message.attach(MIMEText(html_summary, "html", "utf-8"))

        # ç™¼é€éƒµä»¶
        with smtplib.SMTP_SSL(smtp_server, smtp_port) as server:
            server.login(smtp_user, smtp_password)
            server.sendmail(
                smtp_user,
                all_recipients,
                message.as_string(),
            )
        print(f"Email sent successfully to {recipient_email} and CC: {smtp_cc_emails if smtp_cc_emails else 'none'}")
    except Exception as e:
        print(f"Failed to send email: {e}")


# LLM1 è¨­å®š (ä¸»è¦æ¨¡å‹)
llm_api_key = os.environ.get("LLM_API_KEY", os.environ.get("OPENAI_API_KEY", "YOUR_API_KEY"))  # å‘å¾Œå…¼å®¹
model = os.environ.get("LLM_MODEL", "gpt-4o-mini")
base_url = os.environ.get("LLM_BASE_URL", "https://api.openai.com/v1")

# LLM2 è¨­å®š (å‚™ç”¨æ¨¡å‹,å¯é¸)
llm2_api_key = os.environ.get("LLM2_API_KEY", "")
llm2_model = os.environ.get("LLM2_MODEL", "")
llm2_base_url = os.environ.get("LLM2_BASE_URL", "")
use_llm2 = bool(llm2_api_key and llm2_model and llm2_base_url)  # åªæœ‰ä¸‰å€‹éƒ½è¨­å®šæ‰å•Ÿç”¨ LLM2

# Telegram è¨­å®š
telegram_token = os.environ.get("TELEGRAM_TOKEN", "xxx")
allowed_users = os.environ.get("ALLOWED_USERS", "")
show_processing = int(os.environ.get("SHOW_PROCESSING", "1"))

# å…¶ä»–è¨­å®š
lang = os.environ.get("TS_LANG", "ç¹é«”ä¸­æ–‡")
chunk_size = int(os.environ.get("CHUNK_SIZE", 2100))
use_audio_fallback = int(os.environ.get("USE_AUDIO_FALLBACK", "0"))

# GROQ API Key (ç”¨æ–¼ Whisper èªéŸ³è½‰æ–‡å­—)
groq_api_key = os.environ.get("GROQ_API_KEY", "YOUR_GROQ_API_KEY")

# å¯ç”¨çš„ LLM æ¨¡å‹åˆ—è¡¨ (ç”± LLM_MODEL å’Œ LLM2_MODEL çµ„æˆ)
def get_available_models():
    models = []
    if model:
        models.append(model)
    if llm2_model and llm2_model not in models:
        models.append(llm2_model)
    return models if models else ["gpt-4o-mini"]  # é è¨­å‚™ç”¨

# è§£ç­”ä¹‹æ›¸ API URL
ANSWER_BOOK_API = os.environ.get("ANSWER_BOOK_API", "http://answerbook.david888.com/answersOriginal")

# æ·»åŠ  mongodb ç´€éŒ„åŠŸèƒ½
mongo_uri = os.environ.get("MONGO_URI", "")
mongo_client = MongoClient(mongo_uri)
db = mongo_client["bot_database"]
summary_collection = db["summaries"]

# èªè¨€é…ç½®
SUPPORTED_LANGUAGES = {
    'zh-TW': 'ç¹é«”ä¸­æ–‡',
    'en': 'English'
}

# ç¹é«”ä¸­æ–‡ System Prompt
SYSTEM_PROMPT_ZH = (
    "è«‹å°‡ä»¥ä¸‹åŸå§‹å½±ç‰‡å…§å®¹ç¸½çµç‚ºäº”å€‹éƒ¨åˆ†ï¼Œ**è«‹ä½¿ç”¨ Markdown èªæ³•é€²è¡Œè±å¯Œçš„æ’ç‰ˆï¼ˆä¾‹å¦‚ï¼š# æ¨™é¡Œã€**ç²—é«”**ã€- æ¸…å–®ç­‰ï¼‰**ï¼Œæ•´é«”èªè¨€ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œçµæ§‹éœ€æ¸…æ¥šã€æœ‰æ¢ç†ã€‚äº”å€‹éƒ¨åˆ†ä¹‹é–“è«‹ç”¨åˆ†éš”ç·šå€éš”ã€‚\n\n"
    "**é‡è¦æé†’**ï¼šå…§å®¹ä¸­å¯èƒ½åŒ…å«å‰µä½œè€…çš„æ¥­é…å»£å‘Šæˆ–è´ŠåŠ©å•†æ¨å»£ï¼ˆå¦‚ VPNã€è¨‚é–±æœå‹™ã€App æ¨å»£ã€æŠ˜æ‰£ç¢¼ç­‰ï¼‰ï¼Œè«‹è‡ªå‹•è­˜åˆ¥ä¸¦**ç•¥éé€™äº›å»£å‘Šå…§å®¹**ï¼Œä¸è¦ç´å…¥æ‘˜è¦ä¸­ã€‚åªç¸½çµå½±ç‰‡çš„æ ¸å¿ƒçŸ¥è­˜å…§å®¹ã€‚\n\n"
    "### â“µ ã€å®¹æ˜“æ‡‚ Easy Knowã€‘\nä½¿ç”¨ç°¡å–®æ˜“æ‡‚ã€ç”Ÿæ´»åŒ–çš„èªè¨€ï¼Œå°‡å…§å®¹**æ¿ƒç¸®æˆä¸€æ®µç´„120ï½200å­—**çš„èªªæ˜ï¼Œ**é©åˆåäºŒæ­²å…’ç«¥ç†è§£**ã€‚å¯ä½¿ç”¨æ¯”å–»æˆ–ç°¡åŒ–é¡æ¯”å¹«åŠ©ç†è§£ã€‚\n\n"
    "### â“¶ ã€ç¸½çµ Overall Summaryã€‘\næ’°å¯«ç´„**300å­—ä»¥ä¸Š**çš„æ‘˜è¦ï¼Œå®Œæ•´æ¦‚æ‹¬å½±ç‰‡çš„**ä¸»è¦è­°é¡Œã€è«–é»èˆ‡çµè«–**ï¼Œèªæ°£å‹™å¯¦ã€æ¸…æ¥šï¼Œé¿å…è‰±æ¾€è©å½™ã€‚\n\n"
    "### â“· ã€è§€é» Viewpointsã€‘\nåˆ—å‡ºå½±ç‰‡ä¸­æåˆ°çš„**3ï½7å€‹ä¸»è¦è§€é»**ï¼Œæ¯é»ä»¥æ¸…å–®ï¼ˆListï¼‰æ–¹å¼å‘ˆç¾ï¼Œä¸¦å¯åŠ å…¥ç°¡çŸ­è©•è«–æˆ–è£œå……èªªæ˜ã€‚\n\n"
    "### â“¸ ã€æ‘˜è¦ Abstractã€‘\nåˆ—å‡º**6ï½10å€‹é—œéµé‡é»å¥**ï¼Œæ¯é»ç°¡çŸ­æœ‰åŠ›ï¼Œä½œç‚ºæ¸…å–®é …ç›®ï¼Œé©ç•¶æ­é…åˆé©çš„è¡¨æƒ…ç¬¦è™Ÿï¼ˆå¦‚âœ…ã€âš ï¸ã€ğŸ“Œï¼‰ä»¥å¼·èª¿é‡é»è³‡è¨Šã€‚\n\n"
    "â“¹ ã€FAQ æ¸¬é©—ã€‘ï¼šæ ¹æ“šå…§å®¹ç”¢å‡º**ä¸‰é¡Œé¸æ“‡é¡Œ**ï¼Œæ¯é¡Œæœ‰ Aã€Bã€Cã€D å››å€‹é¸é …ï¼Œä¸¦åœ¨æ¯é¡Œå¾Œé™„ä¸Šæ­£ç¢ºç­”æ¡ˆåŠç°¡çŸ­è§£é‡‹ã€‚é¡Œç›®æ‡‰æ¶µè“‹å…§å®¹çš„é‡è¦æ¦‚å¿µæˆ–é—œéµçŸ¥è­˜é»ã€‚\n\n"
)

# è‹±æ–‡ System Prompt
SYSTEM_PROMPT_EN = (
    "Please summarize the following content into five sections. **Please use Markdown syntax for rich formatting (e.g., # headers, **bold**, - lists, etc.)**. The output should be in English with a clear and well-organized structure. Separate each section with a divider line.\n\n"
    "**Important**: The content may contain sponsored advertisements or promotions from the creator (such as VPN services, subscription services, app promotions, discount codes, etc.). Please automatically identify and **skip these promotional contents** - do not include them in the summary. Only summarize the core knowledge content of the video.\n\n"
    "### â“µ ã€Easy Knowã€‘\nUse simple, accessible language to condense the content into approximately 120-200 words, suitable for a twelve-year-old to understand. Use analogies or simplified comparisons to aid comprehension.\n\n"
    "### â“¶ ã€Overall Summaryã€‘\nWrite a summary of approximately 300 words or more, comprehensively covering the **main topics, arguments, and conclusions**. Use a practical and clear tone, avoiding obscure vocabulary.\n\n"
    "### â“· ã€Viewpointsã€‘\nList **3-7 main viewpoints** mentioned in the content. Present each point in list form, and add brief comments or supplementary explanations.\n\n"
    "### â“¸ ã€Abstractã€‘\nList **6-10 key highlight sentences** as a list. Each point should be brief and powerful, prefixed with appropriate emoji symbols (such as âœ…, âš ï¸, ğŸ“Œ) to emphasize key information.\n\n"
    "### â“¹ ã€FAQ Quizã€‘\nGenerate **three multiple-choice questions** based on the content. Each question should have A, B, C, D options, followed by the correct answer and a brief explanation. Questions should cover important concepts or key knowledge points from the content.\n\n"
)


def split_user_input(text):
    paragraphs = text.split('\n')
    paragraphs = [paragraph.strip() for paragraph in paragraphs if paragraph.strip()]
    return paragraphs

def scrape_text_from_url(url):
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded is None:
            return [], "ç„¡æ³•ä¸‹è¼‰è©²ç¶²é çš„å…§å®¹ã€‚"  # è¿”å›å…©å€‹å€¼ï¼šç©ºå…§å®¹å’ŒéŒ¯èª¤æ¶ˆæ¯
        
        text = trafilatura.extract(downloaded, include_formatting=True)
        if text is None or text.strip() == "":
            return [], "æå–çš„å…§å®¹ç‚ºç©ºï¼Œå¯èƒ½è©²ç¶²ç«™ä¸æ”¯æŒè§£æã€‚"  # è¿”å›å…©å€‹å€¼ï¼šç©ºå…§å®¹å’ŒéŒ¯èª¤æ¶ˆæ¯
        
        text_chunks = text.split("\n")
        article_content = [chunk.strip() for chunk in text_chunks if chunk.strip()]
        
        if not article_content:
            return [], "æå–çš„å…§å®¹ç‚ºç©ºã€‚"  # è¿”å›å…©å€‹å€¼ï¼šç©ºå…§å®¹å’ŒéŒ¯èª¤æ¶ˆæ¯
        
        return article_content, None  # è¿”å›å…©å€‹å€¼ï¼šå…§å®¹å’Œç„¡éŒ¯èª¤
    except Exception as e:
        print(f"Error: {e}")
        return [], f"æŠ“å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}"  # è¿”å›å…©å€‹å€¼ï¼šç©ºå…§å®¹å’ŒéŒ¯èª¤ä¿¡æ¯


def summarize(text_array, language='zh-TW', selected_model=None):
    try:
        # å°‡æ‰€æœ‰æ®µè½åˆä½µæˆä¸€å€‹å®Œæ•´çš„æ–‡æœ¬
        full_text = "\n".join(text_array)
        
        # ä½¿ç”¨ jieba çš„ TextRank æ¼”ç®—æ³•éæ¿¾æ‰ç„¡æ„ç¾©è©å½™ (ä»£åè©ã€å‰¯è©ç­‰)
        # allowPOS æŒ‡å®šåªä¿ç•™: åœ°å(ns), åè©(n), å‹•åè©(vn), å‹•è©(v), è‹±æ–‡(eng)
        keywords = jieba.analyse.textrank(full_text, topK=5, allowPOS=('ns', 'n', 'vn', 'v', 'eng'))
        
        # æ ¹æ“šèªè¨€é¸æ“‡å°æ‡‰çš„ system prompt
        if language == 'en':
            system_content = SYSTEM_PROMPT_EN
        else:
            system_content = SYSTEM_PROMPT_ZH
        
        system_messages = [
            {
                "role": "system",
                "content": system_content
            }
        ]
        
        # å»ºæ§‹ promptï¼Œç›´æ¥é™„ä¸Šæ•´å€‹æ–‡æœ¬
        prompt = "ç¸½çµ the following text:\n" + full_text
        
        # å‘¼å« GPT API ç”Ÿæˆæ‘˜è¦
        summary = call_gpt_api(prompt, system_messages, selected_model=selected_model)

        # çµ„åˆ Hashtag å­—ä¸²
        if keywords:
            # ç‚ºäº†é¿å…åœ¨ Telegram / Email çš„ Markdown ä¸­è¢«ç•¶æˆ H1 å¤§æ¨™é¡Œï¼Œ
            # æˆ‘å€‘åœ¨ # å‰é¢åŠ ä¸Šé›¶å¯¬åº¦ç©ºç™½ï¼Œæˆ–ç”¨æ­£å¸¸çš„æ–‡å­—æ ¼å¼ï¼Œé€™è£¡æˆ‘å€‘ä½¿ç”¨æ™®é€šçš„æ–‡å­—å€å¡Šæ ¼å¼æ‹¼æ¥
            # Telegram HTML format won't interpret # format, but Markdown rendering in email will. 
            # æ‰€ä»¥åŠ ä¸Šè·³è„«å­—å…ƒ \ ç¢ºä¿ Email markdown è½‰æ›å®‰å…¨
            hashtag_str = " ".join([f"\\#{kw}" for kw in keywords])
            summary += f"\n\n{hashtag_str}"

        # åŠ å…¥æ©Ÿå™¨äººå®£å‚³èª
        summary += "\n\nâœ¡ Oliå°æ¿ƒç¸® Summary bot ç‚ºæ‚¨æ¿ƒç¸®é‡é» âœ¡"

        return summary
    except Exception as e:
        print(f"Error: {e}")
        return "Unknown error! Please contact the owner. ok@vip.david888.com"

def format_for_telegram(markdown_text):
    """
    å°‡ Markdown è½‰æ›æˆ Telegram æ”¯æ´çš„æœ‰é™ HTML æ¨™ç±¤
    Telegram åƒ…æ”¯æ´ <b>, <i>, <u>, <s>, <a>, <code>, <pre>, <tg-spoiler> ç­‰
    ä¸æ”¯æ´ <h1>~<h6>, <ul>, <li>, <p>, <br> ç­‰æ¨™æº– HTML
    """
    if not markdown_text:
        return markdown_text
        
    try:
        # 1. å°‡ Markdown è½‰æˆå®Œæ•´ HTML
        html = markdown.markdown(markdown_text, extensions=['nl2br'])
        
        # 2. ä½¿ç”¨ BeautifulSoup é€²è¡Œæ¨™ç±¤è½‰æ›èˆ‡éæ¿¾
        soup = BeautifulSoup(html, 'html.parser')
        
        # æŠŠæ¨™é¡Œ (<h1>~<h6>) è½‰æ›ç‚ºç²—é«”ä¸¦åŠ æ›è¡Œ
        for v in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
            new_text = f"<b>{v.get_text()}</b>\n\n"
            v.replace_with(new_text)
            
        # æŠŠæ¸…å–®é … (<li>) è½‰æ›ç‚ºå¸¶æœ‰ bullet point çš„æ–‡å­—
        for li in soup.find_all('li'):
            li.replace_with(f"â€¢ {li.get_text()}\n")
            
        # ç§»é™¤ <ul> å’Œ <ol> çš„å¤–å±¤åŒ…è£¹
        for ul in soup.find_all(['ul', 'ol']):
            ul.unwrap()
            
        # æŠŠ <p> è½‰æ›æˆå¸¶æœ‰æ›è¡Œçš„ç´”æ–‡å­—
        for p in soup.find_all('p'):
            p.replace_with(f"{p.get_text()}\n\n")
            
        # æŠŠ <br> æ›¿æ›ç‚ºå¯¦éš›çš„æ›è¡Œç¬¦è™Ÿ
        for br in soup.find_all('br'):
            br.replace_with("\n")
            
        # æŠŠ <hr> æ›¿æ›ç‚ºåˆ†éš”ç·šæ–‡å­—
        for hr in soup.find_all('hr'):
            hr.replace_with("\n----------\n")
            
        # æŠŠ <strong> è½‰æ›ç‚º <b>
        for strong in soup.find_all('strong'):
            strong.name = 'b'
            
        # æŠŠ <em> è½‰æ›ç‚º <i>
        for em in soup.find_all('em'):
            em.name = 'i'
            
        # å–å¾—ç´”æ–‡å­—ä¸¦åªä¿ç•™ Telegram å…è¨±çš„æ¨™ç±¤
        final_text = str(soup)
        
        # html.parser çš„ unwrap è·Ÿ replace_with å¯èƒ½æœƒç•™ä¸‹å¤šé¤˜çš„å…¨å½¢ç©ºç™½æˆ–ç–ŠåŠ æ›è¡Œï¼Œç°¡å–®æ¸…ç†
        final_text = re.sub(r'\n{3,}', '\n\n', final_text)
        # unescape é¿å… &amp; ç­‰å¯¦é«”åœ¨ Telegram ä¸­é¡¯ç¤ºç•°å¸¸ï¼ˆé›–ç„¶ Telegram HTML mode æœ‰äº›è‡ªå‹•è™•ç†ï¼Œä½†æ¸…ä¹¾æ·¨æ¯”è¼ƒä¿éšªï¼‰
        import html as html_lib
        final_text = html_lib.unescape(final_text)
        
        return final_text.strip()
    except Exception as e:
        print(f"Error formatting for Telegram: {e}")
        return markdown_text # å¦‚æœè½‰æ›å¤±æ•—ï¼Œé€€å›åŸå§‹æ–‡å­—



def is_supported_by_ytdlp(url):
    """
    æª¢æ¸¬ URL æ˜¯å¦è¢« yt-dlp æ”¯æ´çš„å½±ç‰‡ç¶²ç«™
    ä½¿ç”¨é›™é‡æª¢æ¸¬ï¼šURL æ¨¡å¼ + yt-dlp æª¢æ¸¬ï¼Œé¿å…å°‡ä¸€èˆ¬ç¶²ç«™èª¤åˆ¤ç‚ºå½±ç‰‡ç¶²ç«™
    """
    # ç¬¬ä¸€å±¤ï¼šURL æ¨¡å¼æª¢æ¸¬å·²çŸ¥çš„å½±ç‰‡ç¶²ç«™
    video_site_patterns = [
        r'youtube\.com|youtu\.be',
        r'vimeo\.com',
        r'bilibili\.com',
        r'dailymotion\.com',
        r'tiktok\.com',
        r'twitch\.tv',
        r'facebook\.com/watch|fb\.watch',
        r'instagram\.com/(p|reel|tv)',
        r'twitter\.com/.*/status|x\.com/.*/status',
        r'soundcloud\.com',
        r'spotify\.com',
        r'bandcamp\.com',
        r'ted\.com/talks',
        r'coursera\.org',
        r'khanacademy\.org',
        r'archive\.org',
        r'pocketcasts\.com/podcast',
        r'player\.soundon\.fm',
        r'podcasts\.apple\.com'
    ]
    
    # å¦‚æœ URL ä¸åŒ¹é…ä»»ä½•å·²çŸ¥çš„å½±ç‰‡ç¶²ç«™æ¨¡å¼ï¼Œç›´æ¥è¿”å› False
    url_lower = url.lower()
    if not any(re.search(pattern, url_lower) for pattern in video_site_patterns):
        print(f"URL {url} doesn't match known video site patterns")
        return False
    
    # ç¬¬äºŒå±¤ï¼šä½¿ç”¨ yt-dlp é€²è¡Œè©³ç´°æª¢æ¸¬
    try:
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'cookiefile': './cookies.txt',
            'extractor_args': {'youtube': {'player_client': ['default,-web_safari']}},
            'force_ipv4': True,
            'geo_bypass': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # å˜—è©¦æå–è³‡è¨Šè€Œä¸ä¸‹è¼‰
            info = ydl.extract_info(url, download=False)
            if info:
                # æª¢æŸ¥æ˜¯å¦åŒ…å«å½±ç‰‡ç›¸é—œçš„æ¬„ä½
                video_indicators = [
                    'formats',           # å½±ç‰‡æ ¼å¼åˆ—è¡¨
                    'duration',          # å½±ç‰‡é•·åº¦
                    'view_count',        # è§€çœ‹æ¬¡æ•¸
                    'like_count',        # æŒ‰è®šæ•¸
                    'upload_date',       # ä¸Šå‚³æ—¥æœŸ
                    'uploader',          # ä¸Šå‚³è€…
                ]
                
                # å¦‚æœæœ‰ formats æ¬„ä½ä¸”ä¸ç‚ºç©ºï¼Œå¾ˆå¯èƒ½æ˜¯å½±ç‰‡
                if 'formats' in info and info['formats']:
                    return True
                
                # å¦‚æœæœ‰ duration ä¸”å¤§æ–¼ 0ï¼Œå¾ˆå¯èƒ½æ˜¯å½±ç‰‡
                if 'duration' in info and info.get('duration', 0) > 0:
                    return True
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å…¶ä»–å½±ç‰‡ç›¸é—œæ¬„ä½
                if any(key in info for key in video_indicators):
                    return True
                
                return False
    except Exception as e:
        print(f"URL {url} not supported by yt-dlp: {e}")
        return False
    
    return False

def clean_subtitle(subtitle_content):
    # ç§»é™¤ WEBVTT æ¨™é ­
    subtitle_content = re.sub(r'WEBVTT\n\n', '', subtitle_content)
    
    # ç§»é™¤æ™‚é–“æˆ³å’Œä½ç½®è³‡è¨Š
    subtitle_content = re.sub(r'\d{2}:\d{2}:\d{2}\.\d{3} --> \d{2}:\d{2}:\d{2}\.\d{3}.*\n', '', subtitle_content)
    
    # ç§»é™¤ç©ºè¡Œ
    subtitle_content = re.sub(r'\n+', '\n', subtitle_content)
    
    # ç§»é™¤è¡Œé¦–çš„æ•¸å­—æ¨™è¨˜ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
    subtitle_content = re.sub(r'^\d+\n', '', subtitle_content, flags=re.MULTILINE)
    
    return subtitle_content.strip()

def extract_video_transcript(video_url):
    """
    é€šç”¨çš„å½±ç‰‡å­—å¹•æå–å‡½æ•¸ï¼Œæ”¯æ´æ‰€æœ‰ yt-dlp æ”¯æ´çš„ç¶²ç«™
    """
    ydl_opts = {
        'writesubtitles': True,
        'writeautomaticsub': True,
        'skip_download': True,
        'subtitleslangs': ['en','zh-Hant', 'zh-Hans', 'zh-TW', 'zh'],
        'outtmpl': '/tmp/%(id)s.%(ext)s',
        'cookiefile': './cookies.txt',  # æ·»åŠ  cookies.txt æ”¯æ´
        'extractor_args': {'youtube': {'player_client': ['default,-web_safari']}},
        'force_ipv4': True,
        'geo_bypass': True,
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(video_url, download=False)
            video_id = info['id']
            
            if 'subtitles' in info or 'automatic_captions' in info:
                ydl.download([video_url])
                
                subtitle_content = None
                for lang in ['en','zh-Hant', 'zh-Hans', 'zh']:
                    subtitle_file = f"/tmp/{video_id}.{lang}.vtt"
                    if os.path.exists(subtitle_file):
                        with open(subtitle_file, 'r', encoding='utf-8') as file:
                            subtitle_content = file.read()
                        os.remove(subtitle_file)
                        print(f"Found and using {lang} subtitle.")
                        break

                if subtitle_content:
                    # æ¸…ç†å­—å¹•å…§å®¹
                    cleaned_content = clean_subtitle(subtitle_content)
                    return cleaned_content
                else:
                    print("No suitable subtitles found in specified languages.")
                    return "no transcript"
            else:
                print("No subtitles or automatic captions available for this video.")
                return "no transcript"
    except Exception as e:
        print(f"An error occurred: {e}")
        return "error"




def retrieve_video_transcript_from_url(video_url):
    """
    é€šç”¨çš„å½±ç‰‡å­—å¹•è½‰æ–‡å­—å‡½æ•¸ï¼Œæ”¯æ´æ‰€æœ‰ yt-dlp æ”¯æ´çš„ç¶²ç«™
    """
    try:
        subtitle_content = extract_video_transcript(video_url)
        if subtitle_content == "no transcript":
            if use_audio_fallback:
                print("No usable subtitles found. Falling back to audio transcription.")
                return audio_transcription(video_url)
            else:
                return ["è©²å½±ç‰‡æ²’æœ‰å¯ç”¨çš„å­—å¹•ï¼Œä¸”éŸ³é »è½‰æ›åŠŸèƒ½æœªå•Ÿç”¨ã€‚"]

        # æ¸…ç†å­—å¹•å…§å®¹
        cleaned_content = re.sub(r'WEBVTT\n\n', '', subtitle_content)
        cleaned_content = re.sub(r'\d+:\d+:\d+\.\d+ --> \d+:\d+:\d+\.\d+\n', '', cleaned_content)
        cleaned_content = re.sub(r'\n\n', ' ', cleaned_content)

        # å°‡æ¸…ç†å¾Œçš„å…§å®¹åˆ†å‰²æˆchunks
        output_chunks = []
        current_chunk = ""
        for word in cleaned_content.split():
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in retrieve_video_transcript_from_url: {e}")
        return ["ç„¡æ³•ç²å–å­—å¹•æˆ–é€²è¡ŒéŸ³é »è½‰æ›ã€‚"]
    
def audio_transcription(video_url):
    try:
        # ä½¿ç”¨ yt-dlp ä¸‹è¼‰éŸ³é »
        ydl_opts = {
            'format': 'bestaudio[protocol^=http]/best',
            'outtmpl': f'/tmp/{str(uuid.uuid4())}.%(ext)s',
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe',
            'cookiefile': './cookies.txt',  # ä½¿ç”¨ cookies.txt æª”æ¡ˆ
            'extractor_args': {'youtube': {'player_client': ['default,-web_safari']}},
            'force_ipv4': True,
            'geo_bypass': True,
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(video_url, download=True)
            output_path = ydl.prepare_filename(info)

        output_path = output_path.replace(os.path.splitext(output_path)[1], ".mp3")
        audio_file = AudioSegment.from_file(output_path)

        chunk_size = 100 * 1000  # 100 ç§’
        chunks = [audio_file[i:i+chunk_size] for i in range(0, len(audio_file), chunk_size)]

        transcript = ""
        for i, chunk in enumerate(chunks):
            temp_file_path = f"/tmp/{str(uuid.uuid4())}.wav"
            chunk.export(temp_file_path, format="wav")

            curl_command = [
                "curl",
                "https://api.groq.com/openai/v1/audio/transcriptions",
                "-H", f"Authorization: Bearer {os.environ.get('GROQ_API_KEY', 'YOUR_GROQ_API_KEY')}",
                "-H", "Content-Type: multipart/form-data",
                "-F", f"file=@{temp_file_path}",
                "-F", "model=whisper-large-v3"
            ]

            result = subprocess.run(curl_command, capture_output=True, text=True)

            try:
                response_json = json.loads(result.stdout)
                transcript += response_json["text"]
            except KeyError as e:
                print("KeyError:", e)
                print("Response JSON:", response_json)
            except json.JSONDecodeError:
                print("Failed to decode JSON:", result.stdout)

            os.remove(temp_file_path)  # åˆªé™¤è‡¨æ™‚éŸ³è¨Šæ–‡ä»¶

        os.remove(output_path)  # åˆªé™¤ä¸‹è¼‰çš„ mp3 æ–‡ä»¶

        # å°‡è½‰éŒ„æ–‡æœ¬åˆ†å‰²æˆ chunks
        output_sentences = transcript.split()
        output_chunks = []
        current_chunk = ""

        for word in output_sentences:
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '

        if current_chunk:
            output_chunks.append(current_chunk.strip())

        return output_chunks

    except Exception as e:
        print(f"Error in audio_transcription: {e}")
        return ["éŸ³é »è½‰éŒ„å¤±æ•—ã€‚"]    


def is_pocketcasts_url(url):
    """æª¢æŸ¥æ˜¯å¦ç‚º Pocket Casts URL"""
    return 'pocketcasts.com/podcast' in url.lower()

def is_soundon_url(url):
    """æª¢æŸ¥æ˜¯å¦ç‚º SoundOn URL"""
    return 'player.soundon.fm' in url.lower() or 'soundon.fm' in url.lower()

def is_apple_podcast_url(url):
    """æª¢æŸ¥æ˜¯å¦ç‚º Apple Podcast URL"""
    return 'podcasts.apple.com' in url.lower()

def extract_rss_from_pocketcasts(url):
    """
    å¾ Pocket Casts é é¢æå– RSS feed URL
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # å¾é é¢å…§å®¹ä¸­æŸ¥æ‰¾ RSS feed URL
        # Pocket Casts é é¢é€šå¸¸åŒ…å«åŸå§‹ RSS feed ä¿¡æ¯
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # å˜—è©¦å¤šç¨®æ–¹å¼æ‰¾åˆ° RSS feed
        patterns = [
            r'"feedUrl"\s*:\s*"([^"]+)"',
            r'"feed_url"\s*:\s*"([^"]+)"',
            r'"rssUrl"\s*:\s*"([^"]+)"',
            r'feed[Uu]rl["\']?\s*[:=]\s*["\']([^"\',]+)["\']',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response.text)
            if match:
                rss_url = match.group(1)
                # è™•ç†å¯èƒ½çš„è½‰ç¾©å­—ç¬¦
                rss_url = rss_url.replace('\\/', '/')
                print(f"Found RSS feed URL: {rss_url}")
                return rss_url
        
        print("Could not find RSS feed URL in Pocket Casts page")
        return None
        
    except Exception as e:
        print(f"Error extracting RSS from Pocket Casts: {e}")
        return None

def extract_rss_from_soundon(url):
    """
    å¾ SoundOn é é¢æå– RSS feed URL
    SoundOn çš„ RSS feed é€šå¸¸åœ¨é é¢çš„ link æ¨™ç±¤ä¸­
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æŸ¥æ‰¾ RSS feed link æ¨™ç±¤
        rss_link = soup.find('link', {'type': 'application/rss+xml'})
        if rss_link and rss_link.get('href'):
            rss_url = rss_link.get('href')
            print(f"Found SoundOn RSS feed URL: {rss_url}")
            return rss_url
        
        # å˜—è©¦å¾ meta æ¨™ç±¤ä¸­æŸ¥æ‰¾
        meta_rss = soup.find('meta', {'property': 'og:rss'})
        if meta_rss and meta_rss.get('content'):
            rss_url = meta_rss.get('content')
            print(f"Found SoundOn RSS feed URL from meta: {rss_url}")
            return rss_url
        
        # å˜—è©¦å¾é é¢å…§å®¹ä¸­ç”¨æ­£å‰‡è¡¨é”å¼æŸ¥æ‰¾
        patterns = [
            r'"rss"\s*:\s*"([^"]+)"',
            r'"feedUrl"\s*:\s*"([^"]+)"',
            r'https://[^"\s]+\.rss',
            r'https://feeds\.soundon\.fm/[^"\s]+',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response.text)
            if match:
                rss_url = match.group(0) if 'https://' in pattern else match.group(1)
                rss_url = rss_url.replace('\\/', '/')
                print(f"Found SoundOn RSS feed URL: {rss_url}")
                return rss_url
        
        print("Could not find RSS feed URL in SoundOn page")
        return None
        
    except Exception as e:
        print(f"Error extracting RSS from SoundOn: {e}")
        return None

def extract_rss_from_apple_podcast(url):
    """
    å¾ Apple Podcast é é¢æå– RSS feed URL
    Apple Podcast éœ€è¦é€šé iTunes API ä¾†ç²å– RSS feed
    """
    try:
        # å¾ URL ä¸­æå– podcast ID
        # URL æ ¼å¼: https://podcasts.apple.com/{country}/podcast/{name}/id{podcast_id}
        match = re.search(r'/id(\d+)', url)
        if not match:
            print("Could not extract podcast ID from Apple Podcast URL")
            return None
        
        podcast_id = match.group(1)
        print(f"Found Apple Podcast ID: {podcast_id}")
        
        # ä½¿ç”¨ iTunes API æŸ¥è©¢ podcast ä¿¡æ¯
        api_url = f"https://itunes.apple.com/lookup?id={podcast_id}&entity=podcast"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(api_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        
        if data.get('resultCount', 0) > 0:
            results = data.get('results', [])
            for result in results:
                if result.get('kind') == 'podcast' and result.get('feedUrl'):
                    rss_url = result.get('feedUrl')
                    print(f"Found Apple Podcast RSS feed URL: {rss_url}")
                    return rss_url
        
        print("Could not find RSS feed URL from Apple Podcast API")
        return None
        
    except Exception as e:
        print(f"Error extracting RSS from Apple Podcast: {e}")
        return None

def get_latest_podcast_episode(rss_url, max_episodes=1):
    """
    å¾ RSS feed ç²å–æœ€æ–°çš„ podcast episode(s)
    è¿”å› episode æ¨™é¡Œå’ŒéŸ³é » URL åˆ—è¡¨
    """
    try:
        print(f"Fetching RSS feed: {rss_url}")
        feed = feedparser.parse(rss_url)
        
        if not feed.entries:
            print("No episodes found in RSS feed")
            return []
        
        episodes = []
        for entry in feed.entries[:max_episodes]:
            title = entry.get('title', 'Unknown Episode')
            
            # å°‹æ‰¾éŸ³é » URL
            audio_url = None
            
            # æª¢æŸ¥ enclosures (å¸¸è¦‹çš„ podcast éŸ³é »ä½ç½®)
            if hasattr(entry, 'enclosures') and entry.enclosures:
                for enclosure in entry.enclosures:
                    if 'audio' in enclosure.get('type', ''):
                        audio_url = enclosure.get('href') or enclosure.get('url')
                        break
            
            # æª¢æŸ¥ links
            if not audio_url and hasattr(entry, 'links'):
                for link in entry.links:
                    if 'audio' in link.get('type', ''):
                        audio_url = link.get('href')
                        break
            
            # æª¢æŸ¥ media_content
            if not audio_url and hasattr(entry, 'media_content'):
                for media in entry.media_content:
                    if 'audio' in media.get('type', ''):
                        audio_url = media.get('url')
                        break
            
            if audio_url:
                episodes.append({
                    'title': title,
                    'audio_url': audio_url,
                    'description': entry.get('summary', '')
                })
                print(f"Found episode: {title}")
            else:
                print(f"No audio URL found for episode: {title}")
        
        return episodes
        
    except Exception as e:
        print(f"Error parsing RSS feed: {e}")
        return []

def download_and_transcribe_podcast(audio_url):
    """
    ä¸‹è¼‰ podcast éŸ³é »ä¸¦ä½¿ç”¨ Whisper è½‰éŒ„
    """
    try:
        print(f"Downloading podcast audio from: {audio_url}")
        
        # ä¸‹è¼‰éŸ³é »æ–‡ä»¶
        temp_audio_path = f"/tmp/{str(uuid.uuid4())}.mp3"
        response = requests.get(audio_url, stream=True, timeout=300)
        response.raise_for_status()
        
        with open(temp_audio_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        
        print(f"Audio downloaded to {temp_audio_path}")
        
        # è¼‰å…¥éŸ³é »æ–‡ä»¶
        audio_file = AudioSegment.from_file(temp_audio_path)
        
        # åˆ†å‰²æˆè¼ƒå°çš„å¡Šé€²è¡Œè½‰éŒ„(100ç§’ä¸€å¡Š)
        chunk_duration = 100 * 1000  # æ¯«ç§’
        chunks = [audio_file[i:i+chunk_duration] for i in range(0, len(audio_file), chunk_duration)]
        
        print(f"Audio split into {len(chunks)} chunks for transcription")
        
        transcript = ""
        for i, chunk in enumerate(chunks):
            print(f"Transcribing chunk {i+1}/{len(chunks)}")
            temp_chunk_path = f"/tmp/{str(uuid.uuid4())}.wav"
            chunk.export(temp_chunk_path, format="wav")
            
            # ä½¿ç”¨ Groq Whisper API è½‰éŒ„
            curl_command = [
                "curl",
                "https://api.groq.com/openai/v1/audio/transcriptions",
                "-H", f"Authorization: Bearer {groq_api_key}",
                "-H", "Content-Type: multipart/form-data",
                "-F", f"file=@{temp_chunk_path}",
                "-F", "model=whisper-large-v3"
            ]
            
            result = subprocess.run(curl_command, capture_output=True, text=True)
            
            try:
                response_json = json.loads(result.stdout)
                transcript += response_json.get("text", "")
            except (KeyError, json.JSONDecodeError) as e:
                print(f"Error decoding transcription response: {e}")
            
            os.remove(temp_chunk_path)
        
        # æ¸…ç†ä¸‹è¼‰çš„éŸ³é »æ–‡ä»¶
        os.remove(temp_audio_path)
        
        # å°‡è½‰éŒ„æ–‡æœ¬åˆ†å‰²æˆchunks
        output_chunks = []
        current_chunk = ""
        words = transcript.split()
        
        for word in words:
            if len(current_chunk) + len(word) + 1 <= chunk_size:
                current_chunk += word + ' '
            else:
                output_chunks.append(current_chunk.strip())
                current_chunk = word + ' '
        
        if current_chunk:
            output_chunks.append(current_chunk.strip())
        
        return output_chunks
        
    except Exception as e:
        print(f"Error downloading and transcribing podcast: {e}")
        return ["Podcast éŸ³é »è½‰éŒ„å¤±æ•—ã€‚"]

def process_pocketcasts_url(url):
    """
    è™•ç† Pocket Casts URL,æå–ä¸¦è½‰éŒ„æœ€æ–°çš„ podcast episode
    """
    try:
        # 1. å¾ Pocket Casts é é¢æå– RSS feed URL
        rss_url = extract_rss_from_pocketcasts(url)
        if not rss_url:
            return ["ç„¡æ³•å¾ Pocket Casts é é¢æå– RSS feedã€‚"]
        
        # 2. å¾ RSS feed ç²å–æœ€æ–° episode
        episodes = get_latest_podcast_episode(rss_url, max_episodes=1)
        if not episodes:
            return ["ç„¡æ³•å¾ RSS feed ç²å– podcast episodesã€‚"]
        
        episode = episodes[0]
        print(f"Processing episode: {episode['title']}")
        
        # 3. ä¸‹è¼‰ä¸¦è½‰éŒ„éŸ³é »
        transcript_chunks = download_and_transcribe_podcast(episode['audio_url'])
        
        return transcript_chunks
        
    except Exception as e:
        print(f"Error processing Pocket Casts URL: {e}")
        return ["è™•ç† Pocket Casts URL æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"]

def process_soundon_url(url):
    """
    è™•ç† SoundOn URL,æå–ä¸¦è½‰éŒ„æœ€æ–°çš„ podcast episode
    """
    try:
        # 1. å¾ SoundOn é é¢æå– RSS feed URL
        rss_url = extract_rss_from_soundon(url)
        if not rss_url:
            return ["ç„¡æ³•å¾ SoundOn é é¢æå– RSS feedã€‚"]
        
        # 2. å¾ RSS feed ç²å–æœ€æ–° episode
        episodes = get_latest_podcast_episode(rss_url, max_episodes=1)
        if not episodes:
            return ["ç„¡æ³•å¾ RSS feed ç²å– podcast episodesã€‚"]
        
        episode = episodes[0]
        print(f"Processing SoundOn episode: {episode['title']}")
        
        # 3. ä¸‹è¼‰ä¸¦è½‰éŒ„éŸ³é »
        transcript_chunks = download_and_transcribe_podcast(episode['audio_url'])
        
        return transcript_chunks
        
    except Exception as e:
        print(f"Error processing SoundOn URL: {e}")
        return ["è™•ç† SoundOn URL æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"]

def process_apple_podcast_url(url):
    """
    è™•ç† Apple Podcast URL,æå–ä¸¦è½‰éŒ„æœ€æ–°çš„ podcast episode
    """
    try:
        # 1. å¾ Apple Podcast æå– RSS feed URL
        rss_url = extract_rss_from_apple_podcast(url)
        if not rss_url:
            return ["ç„¡æ³•å¾ Apple Podcast æå– RSS feedã€‚"]
        
        # 2. å¾ RSS feed ç²å–æœ€æ–° episode
        episodes = get_latest_podcast_episode(rss_url, max_episodes=1)
        if not episodes:
            return ["ç„¡æ³•å¾ RSS feed ç²å– podcast episodesã€‚"]
        
        episode = episodes[0]
        print(f"Processing Apple Podcast episode: {episode['title']}")
        
        # 3. ä¸‹è¼‰ä¸¦è½‰éŒ„éŸ³é »
        transcript_chunks = download_and_transcribe_podcast(episode['audio_url'])
        
        return transcript_chunks
        
    except Exception as e:
        print(f"Error processing Apple Podcast URL: {e}")
        return ["è™•ç† Apple Podcast URL æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"]

def call_gpt_api(prompt, additional_messages=[], use_llm2_model=False, selected_model=None):
    """å‘¼å« LLM APIã€‚
    - use_llm2_model=True ä¸” LLM2 å·²é…ç½®ï¼Œå‰‡ä½¿ç”¨ LLM2
    - selected_model å¯æŒ‡å®šç‰¹å®šæ¨¡å‹ (ç”¨æˆ¶é€é /model é¸æ“‡)
    """
    if use_llm2_model and use_llm2:
        api_key = llm2_api_key
        api_model = llm2_model
        api_base_url = llm2_base_url
    else:
        api_key = llm_api_key
        api_model = selected_model if selected_model else model
        api_base_url = base_url
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    data = {
        "model": api_model,
        "messages": additional_messages + [
            {"role": "user", "content": prompt}
        ],
    }

    try:
        response = requests.post(f"{api_base_url}/chat/completions", headers=headers, json=data)
        response.raise_for_status()  # å¦‚æœè¿”å›é 200 çš„ç‹€æ…‹ç¢¼æœƒæ‹‹å‡ºç•°å¸¸
        message = response.json()["choices"][0]["message"]["content"].strip()
        return message
    except requests.exceptions.RequestException as e:
        print(f"Request error: {e}")
        return ""


async def handle_start(update, context):
    return await handle('start', update, context)

async def handle_help(update, context):
    return await handle('help', update, context)

async def handle_model(update, context):
    """è™•ç†æ¨¡å‹åˆ‡æ›å‘½ä»¤"""
    return await handle('model', update, context)

async def handle_boa(update, context):
    """å–å›è§£ç­”ä¹‹æ›¸çš„å›ç­”"""
    return await handle('boa', update, context)

async def handle_language(update, context):
    """è™•ç†èªè¨€åˆ‡æ›å‘½ä»¤"""
    return await handle('language', update, context)

async def handle_clear_context(update, context):
    """æ¸…é™¤å°è©±æ­·å²"""
    return await handle('clear_context', update, context)

async def handle_show_context(update, context):
    """é¡¯ç¤ºç•¶å‰å°è©±ä¸Šä¸‹æ–‡"""
    return await handle('show_context', update, context)

async def handle_summarize(update, context):
     return await handle('summarize', update, context)


async def handle_file(update, context):
    return await handle('file', update, context)

# async def handle_button_click(update, context):
#     return await handle('button_click', update, context)
async def handle_button_click(update, context):
    """è™•ç†æŒ‰éˆ•é»æ“Šäº‹ä»¶,åŒ…æ‹¬èªè¨€åˆ‡æ›å’Œæ¨¡å‹é¸æ“‡"""
    query = update.callback_query
    await query.answer()
    
    # è™•ç†èªè¨€åˆ‡æ›æŒ‰éˆ•
    if query.data.startswith('lang_'):
        language = query.data.split('_')[1]
        context.user_data['language'] = language
        
        lang_name = SUPPORTED_LANGUAGES.get(language, language)
        await query.edit_message_text(
            text=f"âœ… èªè¨€å·²åˆ‡æ›ç‚º: {lang_name}\nLanguage switched to: {lang_name}"
        )
        return
    
    # è™•ç†æ¨¡å‹åˆ‡æ›æŒ‰éˆ•
    if query.data.startswith('model_'):
        selected_model = query.data[6:]  # å»æ‰ 'model_' å‰ç¶´
        available_models = get_available_models()
        if selected_model in available_models:
            context.user_data['selected_model'] = selected_model
            await query.edit_message_text(
                text=f"âœ… æ¨¡å‹å·²åˆ‡æ›ç‚º: {selected_model}"
            )
        else:
            await query.edit_message_text(
                text=f"âŒ æ¨¡å‹ä¸å¯ç”¨: {selected_model}"
            )
        return
    
    # å…¶ä»–æŒ‰éˆ•è™•ç†å¯ä»¥åœ¨é€™è£¡æ·»åŠ 

async def handle_yt2audio(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:  # æª¢æŸ¥æ˜¯å¦æœ‰æä¾› URL
        await context.bot.send_message(chat_id=chat_id, text="è«‹æä¾›ä¸€å€‹å½±ç‰‡çš„ URLã€‚ä¾‹å¦‚ï¼š/yt2audio å½±ç‰‡URL")
        return

    url = user_input[1]  # å–å¾—å½±ç‰‡ URL

    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åç¨±
        temp_uuid = str(uuid.uuid4())
        output_template = f"/tmp/{temp_uuid}.%(ext)s"

        # ä½¿ç”¨ yt-dlp ä¸‹è¼‰éŸ³é »
        ydl_opts = {
            'format': 'bestaudio/best',
            'outtmpl': output_template,  # ç›´æ¥ä½¿ç”¨é€™å€‹æ¨¡æ¿ä¾†ç”Ÿæˆæ–‡ä»¶å
            'ffmpeg_location': '/usr/bin/ffmpeg',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'ffprobe_location': '/usr/bin/ffprobe',
            'cookiefile': './cookies.txt',  # æ·»åŠ  cookies.txt æ”¯æ´
            'extractor_args': {'youtube': {'player_client': ['default,-web_safari']}},
            'force_ipv4': True,
            'geo_bypass': True,
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)  # ä¸‹è¼‰éŸ³é »

        # ç¢ºä¿ç²å–åˆ°çš„ mp3 æ–‡ä»¶åæ­£ç¢º
        output_path = f"/tmp/{temp_uuid}.mp3"

        # å‚³é€éŸ³é »æª”æ¡ˆçµ¦ Telegram user
        with open(output_path, 'rb') as audio:
            await context.bot.send_audio(chat_id=chat_id, audio=audio)

        os.remove(output_path)  # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ       

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="ä¸‹è¼‰æˆ–å‚³é€éŸ³é »å¤±æ•—ã€‚è«‹æª¢æŸ¥è¼¸å…¥çš„å½±ç‰‡ URL æ˜¯å¦æ­£ç¢ºã€‚")
        


async def handle_yt2text(update, context):
    chat_id = update.effective_chat.id
    user_input = update.message.text.split()

    if len(user_input) < 2:
        await context.bot.send_message(chat_id=chat_id, text="è«‹æä¾›ä¸€å€‹å½±ç‰‡çš„ URLã€‚ä¾‹å¦‚ï¼š/yt2text å½±ç‰‡URL")
        return

    url = user_input[1]

    try:
        output_chunks = retrieve_video_transcript_from_url(url)

        if output_chunks and output_chunks[0] in ["è©²å½±ç‰‡æ²’æœ‰å¯ç”¨çš„å­—å¹•ã€‚", "ç„¡æ³•ç²å–å­—å¹•ï¼Œä¸”éŸ³é »è½‰æ›åŠŸèƒ½æœªå•Ÿç”¨ã€‚"]:
            await context.bot.send_message(chat_id=chat_id, text=output_chunks[0])
            return

        # è™•ç†æ­£å¸¸æƒ…æ³çš„ä»£ç¢¼
        temp_file_path = f"/tmp/{str(uuid.uuid4())}.txt"
        with open(temp_file_path, 'w', encoding='utf-8') as file:
            for chunk in output_chunks:
                file.write(chunk + "\n")

        with open(temp_file_path, 'rb') as txt_file:
            await context.bot.send_document(chat_id=chat_id, document=txt_file, filename="transcript.txt")

        os.remove(temp_file_path)  # åˆªé™¤è‡¨æ™‚æª”æ¡ˆ

    except Exception as e:
        print(f"Error: {e}")
        await context.bot.send_message(chat_id=chat_id, text="ä¸‹è¼‰æˆ–è½‰æ›æ–‡æœ¬å¤±æ•—ã€‚è«‹æª¢æŸ¥è¼¸å…¥çš„å½±ç‰‡ URL æ˜¯å¦æ­£ç¢ºã€‚")

def get_video_title(video_url):
    """
    ä½¿ç”¨ yt-dlp æå–å½±ç‰‡æ¨™é¡Œï¼Œæ”¯æ´æ‰€æœ‰ yt-dlp æ”¯æ´çš„ç¶²ç«™
    """
    try:
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'cookiefile': './cookies.txt',
            'extractor_args': {'youtube': {'player_client': ['default,-web_safari']}},
            'force_ipv4': True,
            'geo_bypass': True,
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(video_url, download=False)
            return info.get('title', 'å½±ç‰‡')
    except Exception as e:
        print(f"Error extracting video title: {e}")
        return "å½±ç‰‡"

def get_web_title(user_input):
    """
    æ ¹æ“šç”¨æˆ¶æä¾›çš„ URLï¼ŒæŠ“å–ç¶²é å…§å®¹ä¸¦æå–æ¨™é¡Œã€‚
    æ”¯æ´æ‰€æœ‰ yt-dlp æ”¯æ´çš„å½±ç‰‡ç¶²ç«™ä»¥åŠä¸€èˆ¬ç¶²é 
    """
    # é¦–å…ˆæª¢æŸ¥æ˜¯å¦ç‚º yt-dlp æ”¯æ´çš„å½±ç‰‡ç¶²ç«™
    if is_supported_by_ytdlp(user_input):
        return get_video_title(user_input)
    
    try:
        # ä½¿ç”¨ trafilatura æŠ“å–ç¶²é å…§å®¹
        downloaded = trafilatura.fetch_url(user_input)
        if downloaded is None:
            print(f"Failed to download content from {user_input}")
            return "ç„¡æ³•ä¸‹è¼‰è©²ç¶²é çš„å…§å®¹ã€‚"  # è¿”å›å–®å€‹éŒ¯èª¤è¨Šæ¯
        
        # ä½¿ç”¨ BeautifulSoup è§£æç¶²é ä¾†æå–æ¨™é¡Œ
        soup = BeautifulSoup(downloaded, "lxml")
        title = soup.title.string if soup.title else "ç„¡æ³•æå–æ¨™é¡Œ"
        return title
    
    except Exception as e:
        print(f"Error occurred while fetching title: {e}")
        return "æŠ“å–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ã€‚"  # æ•æ‰ç•°å¸¸ä¸¦è¿”å›éŒ¯èª¤è¨Šæ¯
    
        
def process_user_input(user_input):
    """
    è™•ç†ç”¨æˆ¶è¼¸å…¥çš„æ–‡å­—æˆ–ç¶²å€ï¼Œä¸¦è¿”å›é©ç•¶çš„æ–‡æœ¬å…§å®¹æ•¸çµ„
    """
    url_pattern = re.compile(r"https?://")

    if url_pattern.match(user_input):
        # æª¢æŸ¥æ˜¯å¦ç‚º Pocket Casts URL
        if is_pocketcasts_url(user_input):
            # è™•ç† Pocket Casts podcast
            text_array = process_pocketcasts_url(user_input)
        # æª¢æŸ¥æ˜¯å¦ç‚º SoundOn URL
        elif is_soundon_url(user_input):
            # è™•ç† SoundOn podcast
            text_array = process_soundon_url(user_input)
        # æª¢æŸ¥æ˜¯å¦ç‚º Apple Podcast URL
        elif is_apple_podcast_url(user_input):
            # è™•ç† Apple Podcast
            text_array = process_apple_podcast_url(user_input)
        # æª¢æŸ¥æ˜¯å¦ç‚º yt-dlp æ”¯æ´çš„å½±ç‰‡ç¶²ç«™
        elif is_supported_by_ytdlp(user_input):
            # å¦‚æœæ˜¯å½±ç‰‡ç¶²å€ï¼Œèª¿ç”¨é€šç”¨å­—å¹•è™•ç†å‡½æ•¸
            text_array = retrieve_video_transcript_from_url(user_input)
        else:
            # å¦‚æœæ˜¯ä¸€èˆ¬çš„ URLï¼Œèª¿ç”¨ç¶²é æŠ“å–å‡½æ•¸
            text_array, error = scrape_text_from_url(user_input)
            if error:
                return [], error
    else:
        # è™•ç†ä¸€èˆ¬çš„æ–‡å­—è¼¸å…¥
        text_array = split_user_input(user_input)

    return text_array

def clear_old_commands(telegram_token):
    url = f"https://api.telegram.org/bot{telegram_token}/deleteMyCommands"
    
    scopes = ["default", "all_private_chats", "all_group_chats", "all_chat_administrators"]
    
    for scope in scopes:
        data = {"scope": {"type": scope}}
        response = requests.post(url, json=data)
        
        if response.status_code == 200:
            print(f"Old commands cleared successfully for scope: {scope}")
        else:
            print(f"Failed to clear old commands for scope {scope}: {response.text}")

def set_my_commands(telegram_token):
    clear_old_commands(telegram_token)  # æ¸…é™¤èˆŠçš„å‘½ä»¤
    url = f"https://api.telegram.org/bot{telegram_token}/setMyCommands"
    commands = [
        {"command": "start", "description": "ç¢ºèªæ©Ÿå™¨äººæ˜¯å¦åœ¨ç·š"},
        {"command": "help", "description": "é¡¯ç¤ºæ­¤å¹«åŠ©è¨Šæ¯"},
        {"command": "lang", "description": "åˆ‡æ›èªè¨€ Switch language"},
        {"command": "model", "description": "åˆ‡æ›/åˆ—å‡ºæ¨¡å‹ Switch/List models"},
        {"command": "boa", "description": "è§£ç­”ä¹‹æ›¸ Book of Answers"},
        {"command": "context", "description": "é¡¯ç¤ºå°è©±ä¸Šä¸‹æ–‡ Show context"},
        {"command": "clear", "description": "æ¸…é™¤å°è©±æ­·å² Clear history"},
        {"command": "yt2audio", "description": "ä¸‹è¼‰å½±ç‰‡éŸ³é »ï¼ˆæ”¯æ´ YouTubeã€Vimeoã€Bilibili ç­‰ï¼‰"},
        {"command": "yt2text", "description": "å°‡å½±ç‰‡è½‰æˆæ–‡å­—ï¼ˆæ”¯æ´ YouTubeã€Vimeoã€Bilibili ç­‰ï¼‰"},
    ]
    data = {"commands": commands}
    response = requests.post(url, json=data)

    if response.status_code == 200:
        print("Commands set successfully.")
    else:
        print(f"Failed to set commands: {response.text}")

def is_url(text):
    url_pattern = re.compile(r'https?://\S+|www\.\S+')
    return bool(url_pattern.match(text))

async def handle(action, update, context):
    chat_id = update.effective_chat.id
    user_id = update.effective_user.id

    if allowed_users and str(user_id) not in allowed_users.split(','):
        await context.bot.send_message(chat_id=chat_id, text="Sorry, you are not authorized to use this bot.")
        return

    processing_message = None
    if show_processing:
        processing_message = await context.bot.send_message(chat_id=chat_id, text="è™•ç†ä¸­ï¼Œè«‹ç¨å€™...")

    try:
        if action == 'start':
            await context.bot.edit_message_text(chat_id=chat_id, message_id=processing_message.message_id,
                                                text="Oli 333 - Summary Botã€‚v20260117ã€‚å¯ä»¥å¹«æ‚¨è‡ªå‹•ç¸½çµç‚ºç¹é«”ä¸­æ–‡æˆ–è‹±æ–‡çš„å…§å®¹ã€‚")
        elif action == 'help':
            help_text = """
   I can summarize text, URLs, PDFs, video and podcast content for you. 
   è«‹ç›´æ¥è¼¸å…¥ URL æˆ–æƒ³è¦ç¸½çµçš„æ–‡å­—æˆ–PDFï¼Œç„¡è«–æ˜¯ä½•ç¨®èªè¨€ï¼Œæˆ‘éƒ½æœƒå¹«ä½ è‡ªå‹•ç¸½çµç‚ºç¹é«”ä¸­æ–‡çš„å…§å®¹ã€‚
   æ”¯æ´å½±ç‰‡ç¶²ç«™ï¼šYouTubeã€Vimeoã€Bilibiliã€Dailymotionã€TikTokã€Twitch ç­‰ 1000+ ç¶²ç«™
   æ”¯æ´ Podcastï¼šPocket Castsã€SoundOnã€Apple Podcast åŠå„ç¨® RSS feed podcast
   Here are the available commands:
     /start - Start the bot
     /help - Show this help message
     /lang - Switch language (åˆ‡æ›èªè¨€)
     /model - Switch/List LLM models (åˆ‡æ›/åˆ—å‡ºæ¨¡å‹)
     /boa - Book of Answers è§£ç­”ä¹‹æ›¸
     /context - Show current context (é¡¯ç¤ºå°è©±ä¸Šä¸‹æ–‡)
     /clear - Clear conversation history (æ¸…é™¤å°è©±æ­·å²)
     /yt2audio <Video URL> - Download video audio (æ”¯æ´ YouTubeã€Vimeoã€Bilibili ç­‰)
     /yt2text <Video URL> - Convert video to text (æ”¯æ´ YouTubeã€Vimeoã€Bilibili ç­‰)    
   You can also send me any text or URL to summarize.
   After summarizing, you can ask follow-up questions about the content.
            """
            await context.bot.edit_message_text(chat_id=chat_id, message_id=processing_message.message_id, text=help_text)
        elif action == 'language':
            # é¡¯ç¤ºèªè¨€é¸æ“‡æŒ‰éˆ•
            current_lang = context.user_data.get('language', 'zh-TW')
            current_lang_name = SUPPORTED_LANGUAGES.get(current_lang, 'Unknown')
            
            keyboard = [
                [
                    InlineKeyboardButton("ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡", callback_data='lang_zh-TW'),
                    InlineKeyboardButton("ğŸ‡¬ğŸ‡§ English", callback_data='lang_en')
                ]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=processing_message.message_id,
                text=f"Current language / ç•¶å‰èªè¨€: {current_lang_name}\n\nPlease select a language / è«‹é¸æ“‡èªè¨€:",
                reply_markup=reply_markup
            )
        elif action == 'clear_context':
            # æ¸…é™¤å°è©±æ­·å²
            context.user_data['conversation_history'] = None
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=processing_message.message_id,
                text="âœ… å°è©±æ­·å²å·²æ¸…é™¤ã€‚ä¸‹ä¸€æ¬¡è¼¸å…¥å°‡é–‹å§‹æ–°çš„æ‘˜è¦ã€‚\nConversation history cleared. Next input will start a new summary."
            )
        elif action == 'show_context':
            # é¡¯ç¤ºç•¶å‰å°è©±ä¸Šä¸‹æ–‡
            history = context.user_data.get('conversation_history')
            if history:
                info_text = f"ğŸ“‹ ç•¶å‰å°è©±ä¸Šä¸‹æ–‡ / Current Context:\n\n"
                info_text += f"ğŸ”— ä¾†æº Source: {history.get('source_url', 'N/A')}\n"
                info_text += f"ğŸ“… æ™‚é–“ Time: {history.get('timestamp', 'N/A')}\n"
                info_text += f"ğŸ’¬ å•ç­”è¼ªæ•¸ Q&A rounds: {len(history.get('messages', []))}\n"
                info_text += f"ğŸ“ å…§å®¹é•·åº¦ Content length: {len(history.get('original_content', []))} paragraphs\n\n"
                info_text += "ä½ å¯ä»¥ç¹¼çºŒæå•æˆ–ç™¼é€æ–°çš„ URL é–‹å§‹æ–°æ‘˜è¦ã€‚\nYou can continue asking or send a new URL to start fresh."
            else:
                info_text = "ğŸ“­ ç›®å‰æ²’æœ‰å°è©±æ­·å²ã€‚\nNo conversation history available."
            
            await context.bot.edit_message_text(
                chat_id=chat_id,
                message_id=processing_message.message_id,
                text=info_text
            )
        elif action == 'model':
            # è™•ç†æ¨¡å‹åˆ‡æ›å‘½ä»¤
            args = update.message.text.split()[1:] if update.message.text else []
            current_model = context.user_data.get('selected_model', model)
            available_models = get_available_models()
            
            if args:
                # ç”¨æˆ¶æŒ‡å®šäº†æ¨¡å‹
                requested_model = args[0].strip()
                if requested_model in available_models:
                    context.user_data['selected_model'] = requested_model
                    await context.bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=processing_message.message_id,
                        text=f"âœ… æ¨¡å‹å·²åˆ‡æ›è‡³: {requested_model}"
                    )
                else:
                    models_list = "\n".join([f"  â€¢ {m}" for m in available_models])
                    await context.bot.edit_message_text(
                        chat_id=chat_id,
                        message_id=processing_message.message_id,
                        text=f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {requested_model}\n\nğŸ“‹ å¯ç”¨æ¨¡å‹:\n{models_list}"
                    )
            else:
                # åˆ—å‡ºå¯ç”¨æ¨¡å‹ï¼Œä½¿ç”¨æŒ‰éˆ•é¸æ“‡
                keyboard = []
                for m in available_models:
                    marker = "âœ… " if m == current_model else ""
                    keyboard.append([InlineKeyboardButton(f"{marker}{m}", callback_data=f'model_{m}')])
                reply_markup = InlineKeyboardMarkup(keyboard)
                
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=processing_message.message_id,
                    text=f"ğŸ¤– ç•¶å‰æ¨¡å‹: {current_model}\n\nè«‹é¸æ“‡æ¨¡å‹:",
                    reply_markup=reply_markup
                )
        elif action == 'boa':
            # å–å›è§£ç­”ä¹‹æ›¸çš„å›ç­”
            try:
                response = requests.get(ANSWER_BOOK_API, timeout=10)
                response.raise_for_status()
                data = response.json()
                answer = data.get('answer', 'ç„¡æ³•å–å¾—å›ç­”')
                
                boa_text = f"ğŸ“– è§£ç­”ä¹‹æ›¸ Book of Answers\n\n{answer}"
                
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=processing_message.message_id,
                    text=boa_text
                )
            except Exception as e:
                print(f"Error fetching Book of Answers: {e}")
                await context.bot.edit_message_text(
                    chat_id=chat_id,
                    message_id=processing_message.message_id,
                    text="âŒ ç„¡æ³•å–å¾—è§£ç­”ä¹‹æ›¸çš„å›ç­”"
                )
        # ä¿®æ”¹ handle å‡½æ•¸ä¸­çš„ summarize éƒ¨åˆ†
        elif action == 'summarize':
            try:
                user_input = update.message.text
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºçºŒå•
                history = context.user_data.get('conversation_history')
                if history and not is_url(user_input) and len(user_input) < 500:
                    # è™•ç†çºŒå•
                    language = context.user_data.get('language', 'zh-TW')
                    
                    # æ§‹å»ºå°è©±æ­·å²
                    messages = [
                        {"role": "system", "content": "You are a helpful assistant that answers questions about previously summarized content."}
                    ]
                    
                    # æ·»åŠ åŸå§‹å…§å®¹
                    original_content = "\n".join(history.get('original_content', []))
                    messages.append({"role": "user", "content": f"Original content:\n{original_content[:3000]}"})  # é™åˆ¶é•·åº¦
                    
                    # æ·»åŠ æ‘˜è¦
                    messages.append({"role": "assistant", "content": f"Summary:\n{history.get('summary', '')[:2000]}"})
                    
                    # æ·»åŠ ä¹‹å‰çš„å°è©±
                    for msg in history.get('messages', [])[-3:]:  # åªä¿ç•™æœ€è¿‘3è¼ªå°è©±
                        messages.append(msg)
                    
                    # æ·»åŠ ç•¶å‰å•é¡Œ
                    messages.append({"role": "user", "content": user_input})
                    
                    # å‘¼å« API (ä½¿ç”¨ç”¨æˆ¶é¸æ“‡çš„æ¨¡å‹)
                    selected_model = context.user_data.get('selected_model', None)
                    answer = call_gpt_api(user_input, messages[:-1], selected_model=selected_model)  # messages[:-1] å› ç‚º call_gpt_api æœƒè‡ªå·±æ·»åŠ æœ€å¾Œçš„ user message
                    
                    # ä¿å­˜å°è©±æ­·å²
                    history['messages'].append({"role": "user", "content": user_input})
                    history['messages'].append({"role": "assistant", "content": answer})
                    context.user_data['conversation_history'] = history
                    
                    if show_processing and processing_message:
                        await context.bot.delete_message(chat_id=chat_id, message_id=processing_message.message_id)
                    
                    await context.bot.send_message(chat_id=chat_id, text=f"ğŸ’¬ çºŒå•å›ç­”:\n\n{answer}")
                    return
                
                # æ­£å¸¸çš„æ‘˜è¦æµç¨‹
                text_array = process_user_input(user_input)
                if text_array:
                    # ç²å–ç”¨æˆ¶èªè¨€åå¥½å’Œé¸æ“‡çš„æ¨¡å‹
                    language = context.user_data.get('language', 'zh-TW')
                    selected_model = context.user_data.get('selected_model', None)
                    
                    summary = summarize(text_array, language=language, selected_model=selected_model)
                    if is_url(user_input):
                        original_url = user_input
                        title = get_web_title(user_input)
                        summary_with_original = f"ğŸ“Œ {title}\n\n{summary}\n\nâ–¶ {original_url}"
                    else:
                        original_url = None
                        title = "çŸ­æ–‡ä¹‹æ‘˜è¦"  
                        summary_with_original = f"ğŸ“Œ \n{summary}\n"
                    
                    # ä¿å­˜å°è©±æ­·å²åˆ° context.user_data
                    context.user_data['conversation_history'] = {
                        'original_content': text_array,
                        'summary': summary,
                        'source_url': original_url or 'text input',
                        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                        'messages': [],
                        'language': language
                    }
                    
                    # ç§»é™¤é€™ä¸€è¡Œï¼Œä¸éœ€è¦è½‰ç¾©æ™®é€šæ–‡æœ¬
                    # åœ¨ä½¿ç”¨æ™‚åŠ å…¥æ¢ä»¶åˆ¤æ–·
                    if enable_email:
                        # æ–°å¢ï¼šå°‡æ‘˜è¦å¯„é€åˆ°æŒ‡å®šéƒµç®±
                        # æ³¨æ„ï¼šéœ€è¦ä¸€å€‹ä¸»è¦æ”¶ä»¶äººï¼Œè€Œä¸åƒ…æ˜¯æŠ„é€åˆ—è¡¨
                        if smtp_user:  # ä½¿ç”¨ç™¼ä»¶äººåœ°å€ä½œç‚ºä¸»è¦æ”¶ä»¶äºº
                            send_summary_via_email(summary_with_original, smtp_user, subject=title)
                        else:
                            print("ç„¡æ³•ç™¼é€éƒµä»¶ï¼šç¼ºå°‘ä¸»è¦æ”¶ä»¶äººåœ°å€")
                    
                    # å­˜å„²æ‘˜è¦è³‡è¨Šåˆ° MongoDB
                    summary_data = {
                        "telegram_id": user_id,
                        "url": original_url,
                        "summary": summary_with_original,
                        "original_content": text_array,  # æ–°å¢
                        "language": language,  # æ–°å¢
                        "timestamp": datetime.now()
                    }
                    summary_collection.insert_one(summary_data)
                    
                    if show_processing and processing_message:
                        await context.bot.delete_message(chat_id=chat_id, message_id=processing_message.message_id)
                    
                    # ç™¼é€æ‘˜è¦åˆ° Discord Webhookï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                    if enable_discord_webhook:
                        discord_message = f"ğŸ”” æ–°çš„æ‘˜è¦å·²ç”Ÿæˆï¼š\n{summary_with_original}"
                        send_to_discord(discord_message)
                    
                    # è™•ç†é•·æ¶ˆæ¯ï¼Œå°‡ Markdown è½‰æ›æˆ Telegram æ”¯æ´çš„ HTML
                    formatted_summary = format_for_telegram(summary_with_original)
                    
                    if len(formatted_summary) > 4000:
                        parts = [formatted_summary[i:i+4000] for i in range(0, len(formatted_summary), 4000)]
                        for part in parts:
                            await context.bot.send_message(
                                chat_id=chat_id,
                                text=part,
                                parse_mode='HTML'
                            )
                    else:
                        await context.bot.send_message(
                            chat_id=chat_id,
                            text=formatted_summary,
                            parse_mode='HTML'
                        )
                else:
                    await context.bot.send_message(
                        chat_id=chat_id,
                        text="ç„¡æ³•è™•ç†è¼¸å…¥çš„æ–‡æœ¬ã€‚è«‹ç¢ºä¿æä¾›äº†æœ‰æ•ˆçš„æ–‡æœ¬æˆ–URLã€‚"
                    )
            except Exception as e:
                print(f"Error in summarize action: {e}")
                await context.bot.send_message(
                    chat_id=chat_id,
                    text="è™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
                )
        elif action == 'file':
            import traceback
            try:
                print("=== [DEBUG] handle_file é€²å…¥ ===")
                print(f"update.message.document: {update.message.document}")
                print(f"update.message.photo: {update.message.photo}")
                if update.message.document:
                    file = await update.message.document.get_file()
                    filename = update.message.document.file_name
                    ext = os.path.splitext(filename)[1] if filename else ""
                    print(f"[DEBUG] æ–‡ä»¶æ¨¡å¼ filename={filename}, ext={ext}")
                elif update.message.photo:
                    # å–æœ€å¤§è§£æåº¦çš„åœ–ç‰‡
                    photo = update.message.photo[-1]
                    file = await photo.get_file()
                    filename = "photo.jpg"
                    ext = ".jpg"
                    print(f"[DEBUG] åœ–ç‰‡æ¨¡å¼ filename={filename}, ext={ext}")
                else:
                    print("[DEBUG] ç„¡æ³•å–å¾—æª”æ¡ˆæˆ–åœ–ç‰‡")
                    raise Exception("ç„¡æ³•å–å¾—æª”æ¡ˆæˆ–åœ–ç‰‡")
                file_path = f"/tmp/{file.file_id}{ext}"
                print(f"[DEBUG] file_path={file_path}")
                await file.download_to_drive(file_path)
                print(f"[DEBUG] æª”æ¡ˆå·²ä¸‹è¼‰åˆ° {file_path}")
                
                # åˆ¤æ–·æ˜¯å¦ç‚ºåœ–ç‰‡æª”æ¡ˆ
                image_exts = [".jpg", ".jpeg", ".png", ".bmp", ".gif", ".tiff", ".webp"]
                if ext.lower() in image_exts:
                    print("[DEBUG] é€²å…¥åœ–ç‰‡æ‘˜è¦æ¨¡å¼ï¼Œè‡ªå‹•é¸æ“‡ llm_client")
                    if not base_url or "openai.com" in base_url:
                        from openai import OpenAI
                        client = OpenAI()
                        print("[DEBUG] ä½¿ç”¨ openai.OpenAI() client")
                    else:
                        from litellm import openai as litellm_openai
                        client = litellm_openai.OpenAI(api_key=llm_api_key, base_url=base_url)
                        print(f"[DEBUG] ä½¿ç”¨ litellm.openai.OpenAI client, base_url={base_url}")
                    md = MarkItDown(llm_client=client, llm_model=model)
                else:
                    print("[DEBUG] é€²å…¥æ–‡ä»¶æ‘˜è¦æ¨¡å¼")
                    md = MarkItDown()
                print("[DEBUG] é–‹å§‹ markitdown è½‰æ›")
                try:
                    result = md.convert(file_path)
                    text = result.text_content
                    print(f"[DEBUG] markitdown è½‰æ›å®Œæˆï¼Œtext é•·åº¦={len(text)}")
                except Exception as e:
                    import traceback
                    print(f"[ERROR] markitdown è½‰æ›å¤±æ•—: {e}")
                    traceback.print_exc()
                    raise
                # å¯é¸ï¼šè™•ç†é€²åº¦è¨Šæ¯ï¼Œé€™è£¡ç°¡åŒ–ç‚ºä¸€å‰‡
                progress = "æ­£åœ¨è™•ç†æª”æ¡ˆ..."
                if processing_message:
                    await context.bot.edit_message_text(chat_id=chat_id, message_id=processing_message.message_id, text=progress)
                else:
                    processing_message = await context.bot.send_message(chat_id=chat_id, text=progress)

                os.remove(file_path)
                print(f"[DEBUG] å·²åˆªé™¤æš«å­˜æª” {file_path}")

                # ç›´æ¥å°æ•´å€‹æ–‡æœ¬é€²è¡Œä¸€æ¬¡æ€§æ‘˜è¦ï¼Œä¸éœ€è¦åˆ†å¡Šè™•ç†
                # å› ç‚º LLM å¯ä»¥è™•ç†é«˜é” 1,000,000 å€‹ token
                print(f"[DEBUG] é–‹å§‹å°æ•´å€‹æ–‡æœ¬é€²è¡Œæ‘˜è¦ï¼Œæ–‡æœ¬é•·åº¦: {len(text)} å­—ç¬¦")
                language = context.user_data.get('language', 'zh-TW')
                selected_model = context.user_data.get('selected_model', None)
                summary = summarize([text], language=language, selected_model=selected_model)

                # è½‰ç¾© Markdown ç‰¹æ®Šå­—ç¬¦
                escaped_summary = escape_markdown(summary, version=2)
                print("[DEBUG] æ‘˜è¦å®Œæˆï¼Œæº–å‚™ç™¼é€")

                if processing_message:
                    try:
                        await context.bot.delete_message(chat_id=chat_id, message_id=processing_message.message_id)
                    except Exception as e:
                        print(f"[DEBUG] åˆªé™¤ processing_message å¤±æ•—: {e}")

                # ç™¼é€ PDF æ‘˜è¦åˆ° Discord Webhookï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
                if enable_discord_webhook:
                    discord_message = f"ğŸ”” å·²æˆåŠŸè™•ç†ä¸€ä»½ PDF æ–‡ä»¶ï¼Œæ‘˜è¦å…§å®¹å¦‚ä¸‹ï¼š\n{summary}"
                    send_to_discord(discord_message)

                # åˆ†æ‰¹ç™¼é€æ‘˜è¦
                if len(summary) > 4000:
                    parts = [summary[i:i+4000] for i in range(0, len(summary), 4000)]
                    for part in parts:
                        await context.bot.send_message(chat_id=chat_id, text=part)
                else:
                    await context.bot.send_message(chat_id=chat_id, text=summary)

                if processing_message:
                    try:
                        await context.bot.delete_message(chat_id=chat_id, message_id=processing_message.message_id)
                    except Exception as e:
                        print(f"[DEBUG] åˆªé™¤ processing_message å¤±æ•—: {e}")

            except Exception as e:
                print(f"[ERROR] Error processing file: {e}")
                traceback.print_exc()
                await context.bot.send_message(chat_id=chat_id, text=f"è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
                await context.bot.send_message(chat_id=chat_id, text=f"è™•ç† PDF æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")

    except Exception as e:
        if processing_message:
            await context.bot.edit_message_text(chat_id=chat_id, message_id=processing_message.message_id, text="ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        else:
            await context.bot.send_message(chat_id=chat_id, text="ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚")
        print(f"Error: {e}")

def main():
    try:
        application = ApplicationBuilder().token(telegram_token).build()
        start_handler = CommandHandler('start', handle_start)
        help_handler = CommandHandler('help', handle_help)
        lang_handler = CommandHandler('lang', handle_language)
        language_handler = CommandHandler('language', handle_language)
        model_handler = CommandHandler('model', handle_model)
        boa_handler = CommandHandler('boa', handle_boa)
        clear_handler = CommandHandler('clear', handle_clear_context)
        context_handler = CommandHandler('context', handle_show_context)
        yt2audio_handler = CommandHandler('yt2audio', handle_yt2audio)
        yt2text_handler = CommandHandler('yt2text', handle_yt2text)
        set_my_commands(telegram_token)
        summarize_handler = MessageHandler(filters.TEXT & ~filters.COMMAND, handle_summarize)
        file_handler = MessageHandler(filters.Document.ALL, handle_file)
        file_image_handler = MessageHandler(filters.PHOTO, handle_file)
        button_click_handler = CallbackQueryHandler(handle_button_click)
        application.add_handler(file_handler)
        application.add_handler(file_image_handler)
        application.add_handler(start_handler)
        application.add_handler(help_handler)
        application.add_handler(lang_handler)
        application.add_handler(language_handler)
        application.add_handler(model_handler)
        application.add_handler(boa_handler)
        application.add_handler(clear_handler)
        application.add_handler(context_handler)
        application.add_handler(yt2audio_handler)
        application.add_handler(yt2text_handler)
        application.add_handler(summarize_handler)
        application.add_handler(button_click_handler)
        application.run_polling()
    except Exception as e:
        print(e)

if __name__ == '__main__':
    main()